{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import seaborn\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Draw_random_resources(Num_Res, Cap_pdf_params, DC_pdf_params, Min_Cap = 0, Min_DC = 0, Max_Cap = 10, Max_DC = 1):\n",
    "    # Cap is for capacity, dc is for duty cycle\n",
    "    \n",
    "    #pdf_params are the values of the relevant characteristic statistics that definie the pdf.  In this case it is the loc and scale params, or the mean and standard deviation\n",
    "    \n",
    "    # We draw three random variables that define an individual load:  It's capacity, it's duty cycle, and where it is in the duty cycle.  \n",
    "    #For Future, I could add the length of the cycle in minutes as well.  \n",
    "\n",
    "    \n",
    "    #Drawing our capacity\n",
    "    cap = scipy.stats.norm.rvs(loc=Cap_pdf_params['loc'], scale=Cap_pdf_params['scale'], size=Num_Res)\n",
    "    \n",
    "    #Drawing th loads Duty Cycle\n",
    "    dc = scipy.stats.norm.rvs(loc=DC_pdf_params['loc'], scale=DC_pdf_params['scale'], size=Num_Res)\n",
    "    \n",
    "    for res in range(0,Num_Res):\n",
    "        if cap[res] > Max_Cap:\n",
    "            cap[res] = Max_Cap\n",
    "        elif cap[res] < Min_Cap:\n",
    "            cap[res] = Min_Cap\n",
    "            \n",
    "        if dc[res] > Max_DC:\n",
    "            dc[res] = Max_Dc\n",
    "        elif dc[res] < Min_DC:\n",
    "            dc[res] = Min_DC\n",
    "    \n",
    "    Cap = pd.Series(cap, name = \"Capacity\")\n",
    "    DC = pd.Series(dc, name = \"Duty_Cycle\")\n",
    "    \n",
    "    Resources = pd.concat([Cap, DC], axis = 1)\n",
    "    \n",
    "    return Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Draw_load(Num_Res, Resources, min_changeDC = 0.1):\n",
    "    #Determine where you are in the duty cycle at t=0.\n",
    "    # This is basically drawing a random value between 0 and 1 to say that the load, at the instant of analysis, is \n",
    "    # the random decimal way through the period of the duty cycle.  \n",
    "    lc0 = np.random.uniform(low=0.0, high=1.0, size=Num_Res)\n",
    "    cap = Resources['Capacity'].tolist()\n",
    "    dc = Resources['Duty_Cycle'].tolist()\n",
    "    \n",
    "    load = []\n",
    "    flexUp = []\n",
    "    flexDn = []\n",
    "    for res in range(0,Num_Res):\n",
    "        \n",
    "        if lc0[res] <= dc[res]: #If the value drawn for the inital load condition is less than the duty cycle\n",
    "            load.append(cap[res]) #The load is on\n",
    "            if lc0[res] >= min_changeDC: #If the load is on and the initial load condition is greater than min \n",
    "                flexUp.append(cap[res]) #The resource can shed load up to it's capacity\n",
    "                flexDn.append(0)\n",
    "            else:\n",
    "                flexUp.append(0)\n",
    "                flexDn.append(0)\n",
    "        else:\n",
    "            load.append(0)\n",
    "            if lc0[res] - dc[res] >= min_changeDC: #If the load is off and the initial load condition is greater than min plus the duty cycle\n",
    "                flexUp.append(0)\n",
    "                flexDn.append(cap[res]) #The resource could add load up to it's capacity\n",
    "            else:\n",
    "                flexUp.append(0)\n",
    "                flexDn.append(0)\n",
    "        \n",
    "    LC0 = pd.Series(lc0, name = \"Initial_Condition\")\n",
    "    Load = pd.Series(load, name = \"TCL_Load\")\n",
    "    FlexUp = pd.Series(flexUp, name = \"Up_Flexibility\")\n",
    "    FlexDn = pd.Series(flexDn, name = \"Down_Flexibility\")\n",
    "    \n",
    "    #####  THis should probably change\n",
    "    Result = pd.concat([Resources, LC0, Load, FlexUp, FlexDn], axis = 1)\n",
    "    #####\n",
    "    \n",
    "    return Result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223.43210918173151, 203.11767099874902, 141.21567200393537)\n",
      "    TCL_Load  Up_Flexibility  Down_Flexibility  Capacity  Duty_Cycle  \\\n",
      "0   3.753751        3.753751          0.000000  3.753751    0.480711   \n",
      "1   3.047245        3.047245          0.000000  3.047245    0.371079   \n",
      "2   3.624688        3.624688          0.000000  3.624688    0.576637   \n",
      "3   4.195593        4.195593          0.000000  4.195593    0.501636   \n",
      "4   4.862249        4.862249          0.000000  4.862249    0.389086   \n",
      "5   3.499310        3.499310          0.000000  3.499310    0.492156   \n",
      "6   4.490641        4.490641          0.000000  4.490641    0.677982   \n",
      "7   4.893388        4.893388          0.000000  4.893388    0.540105   \n",
      "8   3.799299        3.799299          0.000000  3.799299    0.488120   \n",
      "9   3.876215        3.876215          0.000000  3.876215    0.514341   \n",
      "10  0.000000        0.000000          4.856218  4.856218    0.526095   \n",
      "11  2.568900        2.568900          0.000000  2.568900    0.551154   \n",
      "12  0.000000        0.000000          3.131660  3.131660    0.698272   \n",
      "13  4.115521        4.115521          0.000000  4.115521    0.560251   \n",
      "14  0.000000        0.000000          0.000000  5.639638    0.515955   \n",
      "15  0.000000        0.000000          3.143932  3.143932    0.468249   \n",
      "16  3.886765        3.886765          0.000000  3.886765    0.556636   \n",
      "17  3.442967        0.000000          0.000000  3.442967    0.566543   \n",
      "18  0.000000        0.000000          4.153316  4.153316    0.505479   \n",
      "19  4.592301        0.000000          0.000000  4.592301    0.643115   \n",
      "20  3.515422        3.515422          0.000000  3.515422    0.635680   \n",
      "21  4.006866        4.006866          0.000000  4.006866    0.614660   \n",
      "22  0.000000        0.000000          4.470433  4.470433    0.619832   \n",
      "23  0.000000        0.000000          0.000000  3.899682    0.658206   \n",
      "24  5.877030        5.877030          0.000000  5.877030    0.628658   \n",
      "25  0.000000        0.000000          4.420371  4.420371    0.510554   \n",
      "26  0.000000        0.000000          3.585505  3.585505    0.741265   \n",
      "27  4.170752        4.170752          0.000000  4.170752    0.602444   \n",
      "28  3.843564        0.000000          0.000000  3.843564    0.456359   \n",
      "29  4.646017        4.646017          0.000000  4.646017    0.384086   \n",
      "..       ...             ...               ...       ...         ...   \n",
      "70  5.331334        5.331334          0.000000  5.331334    0.609968   \n",
      "71  0.000000        0.000000          3.920896  3.920896    0.407161   \n",
      "72  0.000000        0.000000          3.661371  3.661371    0.546627   \n",
      "73  0.000000        0.000000          5.373524  5.373524    0.522976   \n",
      "74  5.240913        5.240913          0.000000  5.240913    0.633801   \n",
      "75  5.413989        5.413989          0.000000  5.413989    0.300619   \n",
      "76  1.518499        1.518499          0.000000  1.518499    0.723439   \n",
      "77  2.701223        2.701223          0.000000  2.701223    0.634633   \n",
      "78  4.493266        4.493266          0.000000  4.493266    0.674206   \n",
      "79  4.787351        4.787351          0.000000  4.787351    0.584576   \n",
      "80  4.332284        4.332284          0.000000  4.332284    0.655985   \n",
      "81  2.628681        2.628681          0.000000  2.628681    0.975700   \n",
      "82  3.105073        3.105073          0.000000  3.105073    0.649685   \n",
      "83  0.000000        0.000000          4.297310  4.297310    0.502722   \n",
      "84  1.578291        1.578291          0.000000  1.578291    0.572660   \n",
      "85  3.400311        3.400311          0.000000  3.400311    0.768326   \n",
      "86  3.952948        3.952948          0.000000  3.952948    0.602353   \n",
      "87  0.000000        0.000000          4.653688  4.653688    0.621983   \n",
      "88  0.000000        0.000000          4.372246  4.372246    0.594488   \n",
      "89  0.000000        0.000000          4.933234  4.933234    0.619914   \n",
      "90  3.366068        3.366068          0.000000  3.366068    0.745204   \n",
      "91  0.000000        0.000000          5.439273  5.439273    0.499550   \n",
      "92  0.000000        0.000000          3.855046  3.855046    0.527195   \n",
      "93  0.000000        0.000000          3.446370  3.446370    0.685327   \n",
      "94  0.000000        0.000000          3.068712  3.068712    0.694877   \n",
      "95  0.000000        0.000000          4.382263  4.382263    0.485182   \n",
      "96  0.000000        0.000000          0.000000  3.826246    0.640535   \n",
      "97  0.000000        0.000000          5.416047  5.416047    0.637948   \n",
      "98  0.000000        0.000000          4.742345  4.742345    0.707134   \n",
      "99  3.763082        3.763082          0.000000  3.763082    0.508323   \n",
      "\n",
      "    Initial_Condition  \n",
      "0            0.413419  \n",
      "1            0.291567  \n",
      "2            0.121510  \n",
      "3            0.372616  \n",
      "4            0.347388  \n",
      "5            0.280212  \n",
      "6            0.169556  \n",
      "7            0.453773  \n",
      "8            0.453900  \n",
      "9            0.481003  \n",
      "10           0.834514  \n",
      "11           0.473631  \n",
      "12           0.856546  \n",
      "13           0.498849  \n",
      "14           0.549517  \n",
      "15           0.676849  \n",
      "16           0.211578  \n",
      "17           0.032758  \n",
      "18           0.945524  \n",
      "19           0.047527  \n",
      "20           0.386217  \n",
      "21           0.391741  \n",
      "22           0.746258  \n",
      "23           0.727587  \n",
      "24           0.479019  \n",
      "25           0.718231  \n",
      "26           0.964697  \n",
      "27           0.495667  \n",
      "28           0.061446  \n",
      "29           0.200999  \n",
      "..                ...  \n",
      "70           0.515061  \n",
      "71           0.958704  \n",
      "72           0.810821  \n",
      "73           0.918764  \n",
      "74           0.184061  \n",
      "75           0.230937  \n",
      "76           0.189755  \n",
      "77           0.568201  \n",
      "78           0.656127  \n",
      "79           0.359982  \n",
      "80           0.223599  \n",
      "81           0.970227  \n",
      "82           0.180271  \n",
      "83           0.913814  \n",
      "84           0.454979  \n",
      "85           0.291826  \n",
      "86           0.444430  \n",
      "87           0.880591  \n",
      "88           0.715844  \n",
      "89           0.871546  \n",
      "90           0.701804  \n",
      "91           0.802866  \n",
      "92           0.847770  \n",
      "93           0.954976  \n",
      "94           0.910843  \n",
      "95           0.965140  \n",
      "96           0.695835  \n",
      "97           0.773690  \n",
      "98           0.950848  \n",
      "99           0.217835  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#Let's Draw our loads and see what it looks like:\n",
    "Num_Res = 100\n",
    "Cap_params = {'loc' : 4.0, 'scale' : 0.75}\n",
    "DC_params = {'loc' : 0.55, 'scale' : 0.1}\n",
    "MinCap = 1.0\n",
    "MaxCap = 7.0\n",
    "MinDC = 0.0\n",
    "MaxDC = 1.0\n",
    "minChange = 0.1\n",
    "#Loads = Draw_random_load(Num_Res, Cap_params, DC_params, min_changeDC = minChange, Min_Cap = MinCap, Min_DC = MinDC, Max_Cap = MaxCap, Max_DC = MaxDC)\n",
    "\n",
    "print(sum(Loads['TCL_Load']), sum(Loads['Up_Flexibility']), sum(Loads['Down_Flexibility']))\n",
    "print(Loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Measured_Power(True_Power, Prop_bias, Prop_noise_var, Zero_drift=0, Zero_noise_var=0, Quantization=0.00001):\n",
    "    # This will apply measurement error to a power value in order to determine the measured value.  \n",
    "\n",
    "    # We consider five types of error:\n",
    "    # (1) Quantization Error -  error caused by the digitization of output \n",
    "    # (2) Zero-point Drift - While we may assume that the calibration of a meter begins \n",
    "        # with no bias at zero loading, over time there may be a small drift in that bias.\n",
    "    # (3) Constant Noise - This is white noise existing in the measurement at any loading condition\n",
    "    # (4) Bias -  Calibration errors or drift, this is proportional to the meter read\n",
    "    # (5) Proportional Noise - treated as gaussian white noise that is proportional to the meter reading\n",
    "    \n",
    "    Zero_Error = Zero_drift + scipy.stats.norm.rvs(loc=0,scale=Zero_noise_var)\n",
    "    Prop_Error = True_Power*(1 + Prop_bias + scipy.stats.norm.rvs(loc=0,scale=Prop_noise_var))\n",
    "    Quantized_meter = Quantization*math.floor((Zero_Error+Prop_error)/Quantization)\n",
    "    \n",
    "    return Quantized_meter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Comments: \n",
    "- The impact on the error of a **_single_** measurement between the types of error we describe (Bias vs. Noise) is indecipherable.  In order to determine the impact of each we must assign measurement error parameters and take repeated measurement snapshots with the same resource to look at the distribution of errors.  \n",
    "- If we draw bias from a random distribution, then in aggregate, we don't expect it to look any different than noise unless we give it a non-zero distribution, and I suppose it could be drawn from a non-normal distribution.  \n",
    "- Define meter classes such that the total error is inside the accuracy of the class\n",
    "- The error  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.norm.rvs(loc=0,scale=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario analysis on the error parameters\n",
    "- Generate random resoure: n = 10, 50, 100, 1000, 10000\n",
    "- The zero-point drift and Constant Noise need to be relative to some quantity.  We will assume that all meters are 200A class, and that service voltage is 240V, single phase.  So the total quantity of constant error will be relative to 48kW.  This seems reasonable, as the amperage class of the meter will be based on the main breaker of a residential service panel, and homes with HVAC units are more likely to have a 200A panel than a 100A panel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
